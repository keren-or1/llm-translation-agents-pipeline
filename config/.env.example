# LLM Translation Pipeline - Environment Configuration
# Copy this file to .env and fill in your actual values
# DO NOT commit .env with real keys to git!

# ============================================================================
# API KEYS - KEEP SECURE!
# ============================================================================

# OpenAI API Key (for GPT models and embeddings)
OPENAI_API_KEY=sk-your-actual-key-here

# Anthropic Claude API Key (alternative to OpenAI)
CLAUDE_API_KEY=sk-your-actual-key-here

# OpenAI API Base URL (usually default)
OPENAI_API_BASE=https://api.openai.com/v1

# Anthropic API Base URL
ANTHROPIC_API_BASE=https://api.anthropic.com

# ============================================================================
# MODEL CONFIGURATION
# ============================================================================

# LLM Model for agents (use one of: gpt-4-turbo, gpt-4, claude-3-opus, claude-3-sonnet)
LLM_MODEL=gpt-4-turbo

# Embedding Model (for vector similarity calculation)
EMBEDDING_MODEL=text-embedding-3-small

# Model temperature (0.0-1.0, lower = more consistent, higher = more creative)
LLM_TEMPERATURE=0.3

# Max tokens per response
LLM_MAX_TOKENS=2000

# Top-p parameter for sampling (0.0-1.0)
LLM_TOP_P=0.9

# ============================================================================
# EXPERIMENT CONFIGURATION
# ============================================================================

# Error rates to test (comma-separated percentages)
ERROR_RATES=0,10,20,30,40,50

# Number of test sentences to process
TEST_BATCH_SIZE=1

# Timeout for each API call in seconds
TIMEOUT_SECONDS=60

# Delay between API calls to avoid rate limiting (seconds)
API_DELAY_SECONDS=1

# ============================================================================
# OUTPUT CONFIGURATION
# ============================================================================

# Output directory for results
OUTPUT_DIR=results/

# Log level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Whether to save intermediate outputs
SAVE_INTERMEDIATE=true

# Results file format (json, csv, both)
RESULTS_FORMAT=both

# ============================================================================
# FEATURE FLAGS
# ============================================================================

# Enable automatic retry on API failure
ENABLE_RETRY=true

# Max retries before giving up
MAX_RETRIES=3

# Enable caching of API responses (to save costs)
ENABLE_CACHE=false

# Cache directory
CACHE_DIR=.cache/

# ============================================================================
# DEBUGGING & MONITORING
# ============================================================================

# Enable verbose logging
VERBOSE=false

# Save raw API responses for debugging
SAVE_API_RESPONSES=false

# API responses directory
API_RESPONSES_DIR=debug/responses/

# Track token usage for cost analysis
TRACK_TOKENS=true

# Tokens tracking file
TOKENS_LOG_FILE=results/analysis/tokens_log.json

# ============================================================================
# EXECUTION MODE
# ============================================================================

# Mode: "interactive" (show prompts), "batch" (silent processing), "test" (dry run)
EXECUTION_MODE=batch

# Whether to prompt for confirmation before API calls
CONFIRM_BEFORE_CALLS=false

# ============================================================================
# END OF CONFIGURATION
# ============================================================================
#
# Instructions:
# 1. Copy this file: cp config/.env.example config/.env
# 2. Edit config/.env with your actual API keys and settings
# 3. Never commit config/.env to git (it's in .gitignore)
# 4. For GitHub sharing, create account with free tier:
#    - OpenAI: https://platform.openai.com/account/api-keys
#    - Claude: https://console.anthropic.com/
